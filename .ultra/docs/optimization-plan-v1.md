# IQFMP ç³»ç»Ÿä¼˜åŒ–æ–¹æ¡ˆ v1.0

> åŸºäºå¤–éƒ¨æµ‹è¯•åé¦ˆçš„æ·±åº¦æ‰«æåˆ†ææŠ¥å‘Š

---

## ä¸€ã€ç°çŠ¶è¯Šæ–­æ€»ç»“

### 1.1 æ ¸å¿ƒé—®é¢˜çŸ©é˜µ

| é—®é¢˜åŸŸ | ä¸¥é‡ç¨‹åº¦ | ç°çŠ¶ | å½±å“ |
|--------|---------|------|------|
| **è¯„ä¼°é“¾è·¯æ–­è£‚** | ğŸ”´ Critical | evaluation æ¨¡å—æœªæ¥å…¥ API | å› å­è¯„ä¼°è¿”å›0æŒ‡æ ‡ |
| **æ•°æ®æŒä¹…åŒ–ä¸å®Œæ•´** | ğŸ”´ Critical | Redis stub + å†…å­˜å­˜å‚¨ | æ•°æ®ä¸¢å¤±é£é™© |
| **Qlib é›†æˆè¡¨é¢åŒ–** | ğŸŸ¡ High | æ‰‹å†™è§£æå™¨ï¼Œæœªç”¨ D.features | è¡¨è¾¾å¼æ”¯æŒæœ‰é™ |
| **Agent ç¼–æ’å­¤ç«‹** | ğŸŸ¡ High | æœªä¸ API/Celery ç»‘å®š | æ— æ³•åˆ†å¸ƒå¼æ‰§è¡Œ |
| **å‘é‡åº“æœªå¯ç”¨** | ğŸŸ¡ High | store.py å®Œæ•´ä½†æœªè°ƒç”¨ | æ— å› å­å»é‡ |
| **System é™æ€å‡æ•°æ®** | ğŸŸ  Medium | ç¡¬ç¼–ç  Agent çŠ¶æ€ | ç›‘æ§ä¸çœŸå® |
| **å‰ç«¯éƒ¨åˆ†å ä½** | ğŸŸ  Medium | Pipeline/LiveTrading æ¨¡æ‹Ÿ | äº¤äº’ä¸å®Œæ•´ |
| **WebSocket ç¼ºå¤±** | ğŸŸ  Medium | ä»…è½®è¯¢æ¨¡å¼ | å®æ—¶æ€§å·® |

### 1.2 æ¨¡å—å®Œæˆåº¦è¯„ä¼°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨¡å—                    â”‚ ä»£ç å®Œæˆ â”‚ é›†æˆå®Œæˆ â”‚ å¯ç”¨æ€§  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ API Routes              â”‚   95%    â”‚   70%    â”‚   70%   â”‚
â”‚ Database Layer          â”‚   90%    â”‚   60%    â”‚   55%   â”‚
â”‚ Factor Evaluation       â”‚   95%    â”‚   30%    â”‚   25%   â”‚
â”‚ Qlib Integration        â”‚   80%    â”‚   50%    â”‚   45%   â”‚
â”‚ Agent Orchestration     â”‚   90%    â”‚   40%    â”‚   35%   â”‚
â”‚ Vector Store            â”‚   85%    â”‚   10%    â”‚   10%   â”‚
â”‚ Celery Tasks            â”‚   60%    â”‚   40%    â”‚   35%   â”‚
â”‚ Frontend Pages          â”‚   80%    â”‚   70%    â”‚   65%   â”‚
â”‚ WebSocket               â”‚    5%    â”‚    0%    â”‚    0%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€é˜¶æ®µ1ï¼šæ‰“é€šå¯è¿è¡Œé—­ç¯ï¼ˆ2-3å‘¨ï¼‰

### 2.1 æ•°æ®ä¸æŒä¹…å±‚æ”¹é€ 

#### ä»»åŠ¡ 1.1: å› å­/ç­–ç•¥ä» Redis åˆ‡æ¢åˆ° TimescaleDB

**é—®é¢˜**: `api/factors/service.py` ç¬¬ 120-150 è¡Œä½¿ç”¨ Redis å­˜å‚¨å› å­ï¼ŒæœªæŒä¹…åŒ–åˆ° DB

**ä¿®æ”¹æ–‡ä»¶**:
- `src/iqfmp/api/factors/service.py`
- `src/iqfmp/db/repositories.py`

**å…·ä½“æ”¹åŠ¨**:
```python
# factors/service.py ä¿®æ”¹
# åŸä»£ç  (L120-125):
async def create_factor(self, request: FactorCreateRequest) -> Factor:
    factor = Factor(id=str(uuid4()), ...)
    await self.redis_client.hset("factors", factor.id, factor.model_dump_json())
    return factor

# æ”¹ä¸º:
async def create_factor(self, request: FactorCreateRequest) -> Factor:
    factor = Factor(id=str(uuid4()), ...)
    # 1. æŒä¹…åŒ–åˆ° TimescaleDB
    db_factor = await self.factor_repo.create(factor)
    # 2. Redis ä»…åšç¼“å­˜
    await self.redis_client.setex(f"factor:{factor.id}", 3600, factor.model_dump_json())
    return db_factor
```

#### ä»»åŠ¡ 1.2: Celery ä»»åŠ¡ç»“æœå†™å›æ•°æ®åº“

**é—®é¢˜**: `celery_app/tasks.py` ç¬¬ 200-250 è¡Œå›æµ‹ä»»åŠ¡ä»…æ¨¡æ‹Ÿæ‰§è¡Œ

**ä¿®æ”¹æ–‡ä»¶**:
- `src/iqfmp/celery_app/tasks.py`
- `src/iqfmp/db/repositories.py` (æ·»åŠ  BacktestResultRepository)

**å…·ä½“æ”¹åŠ¨**:
```python
# tasks.py æ·»åŠ æ•°æ®åº“å†™å…¥
@celery_app.task(bind=True)
def backtest_task(self, backtest_id: str, strategy_id: str, config: dict):
    try:
        # çœŸå®æ‰§è¡Œå›æµ‹
        from iqfmp.core.backtest_engine import BacktestEngine
        engine = BacktestEngine()
        result = engine.run_factor_backtest(...)

        # å†™å…¥æ•°æ®åº“ (æ–°å¢)
        with get_db_session() as session:
            repo = BacktestResultRepository(session)
            repo.save_result(backtest_id, result.metrics, result.equity_curve)

        return {"status": "completed", "metrics": result.metrics.dict()}
    except Exception as e:
        # é”™è¯¯ä¹Ÿè¦è®°å½•
        with get_db_session() as session:
            repo.mark_failed(backtest_id, str(e))
        raise
```

#### ä»»åŠ¡ 1.3: docker-compose è¡¥å…… RabbitMQ

**é—®é¢˜**: Celery broker ä½¿ç”¨ Redisï¼Œç”Ÿäº§å»ºè®®ç”¨ RabbitMQ

**ä¿®æ”¹æ–‡ä»¶**: `docker-compose.yml`

```yaml
# æ·»åŠ  RabbitMQ æœåŠ¡
rabbitmq:
  image: rabbitmq:3.12-management-alpine
  ports:
    - "5672:5672"
    - "15672:15672"
  environment:
    RABBITMQ_DEFAULT_USER: iqfmp
    RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-iqfmp_secret}
  volumes:
    - rabbitmq_data:/var/lib/rabbitmq
  healthcheck:
    test: rabbitmq-diagnostics -q ping
    interval: 30s
    timeout: 10s
    retries: 5

# ä¿®æ”¹ celery-worker ç¯å¢ƒå˜é‡
celery-worker:
  environment:
    - CELERY_BROKER_URL=amqp://iqfmp:${RABBITMQ_PASSWORD}@rabbitmq:5672//
```

---

### 2.2 å› å­è¯„ä¼°é“¾è·¯æ‰“é€š

#### ä»»åŠ¡ 2.1: æ¥å…¥å®Œæ•´çš„ FactorEvaluator

**æ ¸å¿ƒé—®é¢˜**: å­˜åœ¨ä¸¤ä¸ªåŒå `FactorEvaluator`:
- `core/factor_engine.py` (ç®€åŒ–ç‰ˆï¼Œå½“å‰ä½¿ç”¨)
- `evaluation/factor_evaluator.py` (å®Œæ•´ç‰ˆï¼Œæœªä½¿ç”¨)

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/api/factors/service.py`

**å…·ä½“æ”¹åŠ¨**:
```python
# ç¬¬ 256-382 è¡Œ evaluate_factor æ–¹æ³•é‡æ„

# åŸä»£ç :
from iqfmp.core.factor_engine import FactorEngine, FactorEvaluator

# æ”¹ä¸º:
from iqfmp.core.factor_engine import FactorEngine
from iqfmp.evaluation.factor_evaluator import FactorEvaluator, EvaluationConfig
from iqfmp.evaluation.cv_splitter import CryptoCVSplitter, CVSplitConfig
from iqfmp.evaluation.stability_analyzer import StabilityAnalyzer

async def evaluate_factor(
    self,
    factor_id: str,
    splits: list[str],
    market_splits: list[str] = None,
) -> tuple[FactorMetrics, StabilityReport, bool, int]:

    factor = await self.get_factor(factor_id)

    # 1. ä½¿ç”¨ FactorEngine è®¡ç®—å› å­å€¼
    engine = FactorEngine(data_path=get_default_data_path())
    factor_values = engine.compute_factor(factor.code, factor.name)

    # 2. é…ç½®å®Œæ•´è¯„ä¼° (NEW)
    eval_config = EvaluationConfig(
        use_cv_splits=True,
        run_stability_analysis=True,
        include_transaction_costs=True,  # æ–°å¢
    )

    # 3. ä½¿ç”¨ CryptoCVSplitter è¿›è¡Œå¤šç»´åˆ‡åˆ† (NEW)
    cv_config = CVSplitConfig(
        time_split=True,
        market_split=market_splits is not None,
        regime_split=True,  # æ³¢åŠ¨ç‡åˆ¶åº¦
    )
    cv_splitter = CryptoCVSplitter(cv_config)

    # 4. ä½¿ç”¨å®Œæ•´ç‰ˆ FactorEvaluator (NEW)
    evaluator = FactorEvaluator(config=eval_config)
    metrics = evaluator.evaluate(
        factor_values=factor_values,
        forward_returns=engine.get_forward_returns(),
        cv_splitter=cv_splitter,
    )

    # 5. ç¨³å®šæ€§åˆ†æ (NEW)
    stability_analyzer = StabilityAnalyzer()
    stability_report = stability_analyzer.analyze(
        factor_values=factor_values,
        returns=engine.get_forward_returns(),
        market_data=engine.data,
    )

    # 6. åŠ¨æ€é˜ˆå€¼æ£€æŸ¥
    threshold = await self._get_dynamic_threshold(factor.family[0])
    passed = metrics.sharpe > threshold

    # 7. è®°å½•ç ”ç©¶è¯•éªŒ
    trial_number = await self.trial_repo.create(...)

    return metrics, stability_report, passed, trial_number
```

#### ä»»åŠ¡ 2.2: æ·»åŠ äº¤æ˜“æˆæœ¬æ¨¡å‹

**é—®é¢˜**: `FactorEvaluator` ç¼ºå°‘äº¤æ˜“æˆæœ¬/å®¹é‡ä¼°ç®—

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/evaluation/factor_evaluator.py`

**æ–°å¢ä»£ç **:
```python
# åœ¨ FactorEvaluator ç±»ä¸­æ·»åŠ 

def _estimate_transaction_costs(
    self,
    factor_values: pd.Series,
    volume: pd.Series,
    config: TransactionCostConfig = None,
) -> TransactionCostMetrics:
    """
    ä¼°ç®—äº¤æ˜“æˆæœ¬å’Œå®¹é‡çº¦æŸ

    Args:
        factor_values: å› å­å€¼åºåˆ—
        volume: æˆäº¤é‡åºåˆ—
        config: æˆæœ¬é…ç½® (é»˜è®¤: taker_fee=0.0004, slippage_bps=2)

    Returns:
        TransactionCostMetrics:
            - turnover: æ¢æ‰‹ç‡
            - estimated_cost_bps: é¢„ä¼°æˆæœ¬(åŸºç‚¹)
            - capacity_usd: å®¹é‡ä¼°ç®—(ç¾å…ƒ)
            - implementability: å¯å®æ–½æ€§è¯„åˆ† (0-1)
    """
    config = config or TransactionCostConfig()

    # 1. è®¡ç®—æ¢æ‰‹ç‡
    position_changes = factor_values.diff().abs()
    turnover = position_changes.mean()

    # 2. ä¼°ç®—äº¤æ˜“æˆæœ¬
    taker_fee = config.taker_fee  # 0.04%
    slippage = config.slippage_bps / 10000  # 2 bps
    estimated_cost = turnover * (taker_fee + slippage) * 252  # å¹´åŒ–

    # 3. å®¹é‡ä¼°ç®— (åŸºäºæˆäº¤é‡çš„ 1%)
    avg_volume_usd = volume.mean() * config.price_assumption
    capacity_usd = avg_volume_usd * 0.01 * 252  # å¹´åŒ–

    # 4. å¯å®æ–½æ€§è¯„åˆ†
    if estimated_cost < 0.005:  # < 0.5% å¹´åŒ–æˆæœ¬
        implementability = 1.0
    elif estimated_cost < 0.02:  # < 2%
        implementability = 0.7
    else:
        implementability = 0.3

    return TransactionCostMetrics(
        turnover=turnover,
        estimated_cost_bps=estimated_cost * 10000,
        capacity_usd=capacity_usd,
        implementability=implementability,
    )
```

---

### 2.3 Qlib é›†æˆå®Œå–„

#### ä»»åŠ¡ 3.1: ä¿®å¤è¡¨è¾¾å¼è§£æå™¨

**é—®é¢˜**: `core/factor_engine.py` æ‰‹å†™æ­£åˆ™è§£æï¼ŒåµŒå¥—è¡¨è¾¾å¼æ”¯æŒæœ‰é™

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/core/factor_engine.py`

**æ”¹è¿›ç­–ç•¥**: ä¼˜å…ˆä½¿ç”¨ Qlib å®˜æ–¹è§£æï¼Œæ‰‹å†™ä½œä¸ºé™çº§

```python
# ç¬¬ 181-262 è¡Œ _evaluate_expression æ–¹æ³•é‡æ„

def _evaluate_expression(self, expr: str, df: pd.DataFrame) -> pd.Series:
    """
    è¯„ä¼° Qlib è¡¨è¾¾å¼

    ä¼˜å…ˆçº§:
    1. å°è¯• Qlib D.features (å¦‚æœå·²åˆå§‹åŒ–)
    2. é™çº§åˆ°æ‰‹å†™è§£æå™¨
    """
    # 1. ä¼˜å…ˆä½¿ç”¨ Qlib å®˜æ–¹è§£æ
    if self._qlib_initialized and self._can_use_d_features(expr):
        try:
            return self._evaluate_with_qlib(expr, df)
        except Exception as e:
            logger.warning(f"Qlib evaluation failed, falling back: {e}")

    # 2. é™çº§åˆ°å¢å¼ºç‰ˆæ‰‹å†™è§£æå™¨
    return self._evaluate_with_custom_parser(expr, df)

def _evaluate_with_qlib(self, expr: str, df: pd.DataFrame) -> pd.Series:
    """ä½¿ç”¨ Qlib D.features è®¡ç®—"""
    from qlib.data import D

    # è½¬æ¢ DataFrame ç´¢å¼•ä¸º Qlib æ ¼å¼
    instruments = df.index.get_level_values('symbol').unique().tolist()
    result = D.features(
        instruments=instruments,
        fields=[expr],
        start_time=df.index.get_level_values('timestamp').min(),
        end_time=df.index.get_level_values('timestamp').max(),
    )
    return result[expr]

def _evaluate_with_custom_parser(self, expr: str, df: pd.DataFrame) -> pd.Series:
    """å¢å¼ºç‰ˆæ‰‹å†™è§£æå™¨ (æ”¯æŒåµŒå¥—)"""
    # ä½¿ç”¨ tokenizer è€Œéæ­£åˆ™
    tokens = self._tokenize(expr)
    ast = self._parse_tokens(tokens)
    return self._evaluate_ast(ast, df)
```

#### ä»»åŠ¡ 3.2: å®Œå–„ provider_uri é…ç½®

**ä¿®æ”¹æ–‡ä»¶**: `.ultra/config.json` + `src/iqfmp/core/factor_engine.py`

```json
// .ultra/config.json æ·»åŠ 
{
  "qlib": {
    "provider_uri": "~/.qlib/qlib_data/crypto",
    "region": "crypto",
    "default_exchange": "binance",
    "supported_timeframes": ["1m", "5m", "15m", "1h", "4h", "1d"]
  }
}
```

```python
# factor_engine.py ä¿®æ”¹ __init__
def __init__(self, config_path: Optional[Path] = None, ...):
    # åŠ è½½é¡¹ç›®é…ç½®
    self._config = self._load_config(config_path)
    qlib_config = self._config.get("qlib", {})

    # è‡ªåŠ¨åˆå§‹åŒ– Qlib
    if qlib_config.get("provider_uri"):
        self.init_qlib(
            provider_uri=qlib_config["provider_uri"],
            region=qlib_config.get("region", "crypto"),
        )
```

---

### 2.4 å‰åç«¯æ‰“é€š

#### ä»»åŠ¡ 4.1: System API è¿”å›çœŸå®æ•°æ®

**é—®é¢˜**: `api/system/service.py` ç¬¬ 39-84 è¡Œè¿”å›ç¡¬ç¼–ç  Agent çŠ¶æ€

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/api/system/service.py`

```python
# æ”¹é€  get_agents() æ–¹æ³•

async def get_agents(self) -> list[AgentResponse]:
    """è¿”å›çœŸå® Agent çŠ¶æ€"""
    agents = []

    # 1. æŸ¥è¯¢ Celery æ´»è·ƒä»»åŠ¡
    from iqfmp.celery_app.app import celery_app
    active_tasks = celery_app.control.inspect().active() or {}

    # 2. èšåˆ Agent çŠ¶æ€
    agent_definitions = [
        ("agent-factor-gen", "Factor Generator", "factors"),
        ("agent-evaluator", "Factor Evaluator", "evaluation"),
        ("agent-backtest", "Backtest Engine", "backtest"),
        ("agent-orchestrator", "Pipeline Orchestrator", "pipeline"),
    ]

    for agent_id, name, task_prefix in agent_definitions:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒä»»åŠ¡
        active_count = sum(
            1 for worker_tasks in active_tasks.values()
            for task in worker_tasks
            if task.get("name", "").startswith(f"iqfmp.celery_app.tasks.{task_prefix}")
        )

        status = "busy" if active_count > 0 else "idle"
        current_task = None

        if active_count > 0:
            # è·å–å½“å‰ä»»åŠ¡ä¿¡æ¯
            for worker_tasks in active_tasks.values():
                for task in worker_tasks:
                    if task.get("name", "").startswith(f"iqfmp.celery_app.tasks.{task_prefix}"):
                        current_task = task.get("id")
                        break

        agents.append(AgentResponse(
            id=agent_id,
            name=name,
            status=status,
            current_task=current_task,
            last_activity=datetime.now(),
            tasks_completed=await self._get_completed_count(task_prefix),
        ))

    return agents
```

#### ä»»åŠ¡ 4.2: WebSocket æ¨é€å®ç°

**æ–°å¢æ–‡ä»¶**: `src/iqfmp/api/websocket.py`

```python
"""WebSocket æ¨é€æœåŠ¡"""
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict, Set
import asyncio
import json

class ConnectionManager:
    """WebSocket è¿æ¥ç®¡ç†å™¨"""

    def __init__(self):
        self.active_connections: Dict[str, Set[WebSocket]] = {
            "pipeline": set(),
            "mining": set(),
            "trading": set(),
            "system": set(),
        }

    async def connect(self, websocket: WebSocket, channel: str):
        await websocket.accept()
        self.active_connections[channel].add(websocket)

    def disconnect(self, websocket: WebSocket, channel: str):
        self.active_connections[channel].discard(websocket)

    async def broadcast(self, channel: str, message: dict):
        """å¹¿æ’­æ¶ˆæ¯åˆ°æŒ‡å®šé¢‘é“"""
        for connection in self.active_connections[channel]:
            try:
                await connection.send_json(message)
            except:
                self.disconnect(connection, channel)

manager = ConnectionManager()

# åœ¨ main.py ä¸­æ·»åŠ è·¯ç”±
@app.websocket("/ws/{channel}")
async def websocket_endpoint(websocket: WebSocket, channel: str):
    if channel not in manager.active_connections:
        await websocket.close(code=4000)
        return

    await manager.connect(websocket, channel)
    try:
        while True:
            # ä¿æŒè¿æ¥ï¼Œç­‰å¾…å®¢æˆ·ç«¯æ¶ˆæ¯
            data = await websocket.receive_text()
            # å¤„ç†è®¢é˜…è¯·æ±‚ç­‰
    except WebSocketDisconnect:
        manager.disconnect(websocket, channel)
```

#### ä»»åŠ¡ 4.3: å‰ç«¯ LiveTrading é¡µé¢æ¥å…¥çœŸå® API

**é—®é¢˜**: `dashboard/src/hooks/useLiveTrading.ts` å®Œå…¨æ˜¯å®¢æˆ·ç«¯æ¨¡æ‹Ÿ

**ä¿®æ”¹æ–‡ä»¶**: `dashboard/src/hooks/useLiveTrading.ts`

```typescript
// ä»æ¨¡æ‹Ÿæ”¹ä¸ºçœŸå® API + WebSocket

export function useLiveTrading() {
  const [positions, setPositions] = useState<Position[]>([]);
  const [orders, setOrders] = useState<Order[]>([]);
  const [account, setAccount] = useState<AccountInfo | null>(null);
  const wsRef = useRef<WebSocket | null>(null);

  useEffect(() => {
    // 1. åˆå§‹åŠ è½½
    const loadInitialData = async () => {
      const [positionsRes, ordersRes, accountRes] = await Promise.all([
        tradingApi.getPositions(),
        tradingApi.getOrders(),
        tradingApi.getAccount(),
      ]);
      setPositions(positionsRes.data);
      setOrders(ordersRes.data);
      setAccount(accountRes.data);
    };
    loadInitialData();

    // 2. WebSocket å®æ—¶æ›´æ–°
    const ws = new WebSocket(`${WS_BASE_URL}/ws/trading`);
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      switch (data.type) {
        case 'position_update':
          setPositions(prev => updatePosition(prev, data.payload));
          break;
        case 'order_update':
          setOrders(prev => updateOrder(prev, data.payload));
          break;
        case 'account_update':
          setAccount(data.payload);
          break;
      }
    };
    wsRef.current = ws;

    return () => ws.close();
  }, []);

  // ... å…¶ä»–æ–¹æ³•
}
```

---

### 2.5 è¿è¡Œä¸æ ¡éªŒ

#### å¯åŠ¨é¡ºåº

```bash
# 1. å¯åŠ¨åŸºç¡€è®¾æ–½
docker compose up -d timescaledb redis qdrant rabbitmq

# 2. ç­‰å¾…æ•°æ®åº“å°±ç»ª
sleep 10

# 3. åˆå§‹åŒ–æ•°æ®åº“
python scripts/init_db.py

# 4. å¯åŠ¨ Celery Worker
celery -A iqfmp.celery_app.app worker -l info -Q high,default,low &

# 5. å¯åŠ¨åç«¯
uvicorn iqfmp.api.main:app --reload --host 0.0.0.0 --port 8000 &

# 6. å¯åŠ¨å‰ç«¯
cd dashboard && npm run dev &
```

#### éªŒè¯æ¸…å•

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# åˆ›å»ºå› å­
curl -X POST http://localhost:8000/api/v1/factors/ \
  -H "Content-Type: application/json" \
  -d '{"name":"test_momentum","family":["momentum"],"code":"..."}'

# è¯„ä¼°å› å­ (åº”è¿”å›çœŸå®æŒ‡æ ‡)
curl -X POST http://localhost:8000/api/v1/factors/{factor_id}/evaluate \
  -H "Content-Type: application/json" \
  -d '{"splits":["train","valid","test"]}'

# æ£€æŸ¥ç ”ç©¶è´¦æœ¬
curl http://localhost:8000/api/v1/research/ledger

# éªŒè¯ Celery ä»»åŠ¡
curl http://localhost:8000/api/v1/backtest/create \
  -H "Content-Type: application/json" \
  -d '{"strategy_id":"...","config":{...}}'

# æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ (åº”æ˜¾ç¤ºçœŸå®è¿›åº¦)
curl http://localhost:8000/api/v1/backtest/{backtest_id}
```

---

## ä¸‰ã€é˜¶æ®µ2ï¼šè¶…è¶Š RD-Agentï¼ˆ4-6å‘¨ï¼‰

### 3.1 LangGraph ç¼–æ’ä¸ RD-Loop é›†æˆ

#### ä»»åŠ¡ 5.1: å°† RDLoop æš´éœ²ä¸º API

**æ–°å¢æ–‡ä»¶**: `src/iqfmp/api/pipeline/rd_loop_router.py`

```python
from fastapi import APIRouter, BackgroundTasks
from iqfmp.core.rd_loop import RDLoop, LoopConfig

router = APIRouter(prefix="/pipeline/rd-loop", tags=["RD Loop"])

@router.post("/run")
async def run_rd_loop(
    config: LoopConfig,
    background_tasks: BackgroundTasks,
):
    """å¯åŠ¨ RD å¾ªç¯"""
    run_id = str(uuid4())

    # åå°æ‰§è¡Œ
    background_tasks.add_task(
        _execute_rd_loop,
        run_id=run_id,
        config=config,
    )

    return {"run_id": run_id, "status": "started"}

async def _execute_rd_loop(run_id: str, config: LoopConfig):
    """æ‰§è¡Œ RD å¾ªç¯å¹¶å¹¿æ’­è¿›åº¦"""
    loop = RDLoop(config=config)

    # æ³¨å†Œé˜¶æ®µå›è°ƒ
    async def on_phase_change(phase, progress):
        await manager.broadcast("pipeline", {
            "type": "rd_loop_progress",
            "run_id": run_id,
            "phase": phase.value,
            "progress": progress,
        })

    loop.on_phase_change = on_phase_change
    results = loop.run()

    # ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
    await save_rd_loop_results(run_id, results)
```

#### ä»»åŠ¡ 5.2: ä½¿ç”¨ LangGraph æ£€æŸ¥ç‚¹æŒä¹…åŒ–

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/agents/orchestrator.py`

```python
# æ·»åŠ  PostgreSQL æ£€æŸ¥ç‚¹ä¿å­˜å™¨

from langgraph.checkpoint.postgres import PostgresSaver

class DatabaseCheckpointSaver(PostgresSaver):
    """PostgreSQL æ£€æŸ¥ç‚¹ä¿å­˜å™¨"""

    def __init__(self, connection_string: str):
        super().__init__(connection_string)

    async def save(self, checkpoint: Checkpoint) -> str:
        """ä¿å­˜æ£€æŸ¥ç‚¹åˆ° PostgreSQL"""
        # ä½¿ç”¨ LangGraph å®˜æ–¹å®ç°
        return await super().save(checkpoint)

    async def load(self, checkpoint_id: str) -> Optional[Checkpoint]:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        return await super().load(checkpoint_id)

# ä¿®æ”¹ AgentOrchestrator åˆå§‹åŒ–
class AgentOrchestrator:
    def __init__(self, config: OrchestratorConfig):
        # ä½¿ç”¨æ•°æ®åº“æ£€æŸ¥ç‚¹
        self._checkpoint_saver = DatabaseCheckpointSaver(
            connection_string=config.database_url
        )
```

### 3.2 é˜²è¿‡æ‹Ÿåˆä½“ç³»å‡çº§

#### ä»»åŠ¡ 6.1: å®Œå–„ CryptoCVSplitter å¤šç»´åˆ‡åˆ†

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/evaluation/cv_splitter.py`

```python
# æ·»åŠ  Regime åˆ‡åˆ†æ”¯æŒ

class CryptoCVSplitter:
    def split(
        self,
        data: pd.DataFrame,
        regime_column: Optional[str] = None,
    ) -> Iterator[CVSplit]:
        """
        å¤šç»´äº¤å‰éªŒè¯åˆ‡åˆ†

        æ”¯æŒ:
        - æ—¶é—´åˆ‡åˆ† (60/20/20)
        - å¸‚åœºåˆ‡åˆ† (å¤§/ä¸­/å°ç›˜)
        - é¢‘ç‡åˆ‡åˆ† (1h/4h/1d)
        - Regime åˆ‡åˆ† (é«˜æ³¢/ä½æ³¢, è¶‹åŠ¿/éœ‡è¡)
        """
        if self.config.time_split:
            yield from self._time_split(data)

        if self.config.market_split:
            yield from self._market_cap_split(data)

        if self.config.frequency_split:
            yield from self._frequency_split(data)

        if self.config.regime_split:
            yield from self._regime_split(data, regime_column)

    def _regime_split(
        self,
        data: pd.DataFrame,
        regime_column: Optional[str] = None,
    ) -> Iterator[CVSplit]:
        """æŒ‰å¸‚åœºåˆ¶åº¦åˆ‡åˆ†"""
        if regime_column is None:
            # è‡ªåŠ¨æ£€æµ‹åˆ¶åº¦
            volatility = data['close'].pct_change().rolling(20).std()
            regime = pd.cut(
                volatility,
                bins=[0, 0.02, 0.05, float('inf')],
                labels=['low_vol', 'medium_vol', 'high_vol']
            )
        else:
            regime = data[regime_column]

        for regime_name in regime.unique():
            mask = regime == regime_name
            yield CVSplit(
                name=f"regime_{regime_name}",
                train_mask=mask & self._get_train_mask(data),
                test_mask=mask & self._get_test_mask(data),
            )
```

#### ä»»åŠ¡ 6.2: Deflated Sharpe Ratio åŠ¨æ€é˜ˆå€¼

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/evaluation/research_ledger.py`

```python
class DynamicThreshold:
    """
    åŸºäº Deflated Sharpe Ratio çš„åŠ¨æ€é˜ˆå€¼

    å‚è€ƒ: Bailey & LÃ³pez de Prado (2014)
    "The Deflated Sharpe Ratio: Correcting for Selection Bias,
    Backtest Overfitting and Non-Normality"
    """

    def calculate(
        self,
        n_trials: int,
        expected_sharpe: float = 0.0,
        variance_of_sharpe: float = 1.0,
        skewness: float = 0.0,
        kurtosis: float = 3.0,
    ) -> float:
        """
        è®¡ç®— Deflated Sharpe Ratio é˜ˆå€¼

        Args:
            n_trials: å·²è¿›è¡Œçš„è¯•éªŒæ¬¡æ•°
            expected_sharpe: é¢„æœŸ Sharpe (é€šå¸¸ä¸º 0)
            variance_of_sharpe: Sharpe æ–¹å·®
            skewness: æ”¶ç›Šååº¦
            kurtosis: æ”¶ç›Šå³°åº¦

        Returns:
            è°ƒæ•´åçš„ Sharpe é˜ˆå€¼
        """
        # 1. è®¡ç®— Expected Maximum Sharpe (åŸºäº n_trials)
        e_max_sharpe = self._expected_max_sharpe(n_trials, variance_of_sharpe)

        # 2. è®¡ç®— Sharpe çš„æ ‡å‡†è¯¯å·® (è€ƒè™‘éæ­£æ€æ€§)
        se_sharpe = self._sharpe_standard_error(
            n_observations=252,  # å‡è®¾ä¸€å¹´
            skewness=skewness,
            kurtosis=kurtosis,
        )

        # 3. Deflated Sharpe Ratio é˜ˆå€¼
        # è¦æ±‚: SR_observed > E[max(SR)] + z_alpha * SE(SR)
        z_alpha = 1.96  # 95% ç½®ä¿¡åº¦
        threshold = e_max_sharpe + z_alpha * se_sharpe

        return max(threshold, self.min_threshold)

    def _expected_max_sharpe(self, n: int, variance: float) -> float:
        """æœŸæœ›æœ€å¤§ Sharpe (åŸºäºæ­£æ€åˆ†å¸ƒçš„ Order Statistics)"""
        from scipy.stats import norm

        # E[max] â‰ˆ Î¦^(-1)(1 - 1/n) * sqrt(variance)
        if n <= 1:
            return 0.0

        quantile = norm.ppf(1 - 1 / n)
        return quantile * np.sqrt(variance)

    def _sharpe_standard_error(
        self,
        n_observations: int,
        skewness: float,
        kurtosis: float,
    ) -> float:
        """
        Sharpe Ratio æ ‡å‡†è¯¯å·® (Lo, 2002)

        SE(SR) = sqrt((1 + 0.5*SR^2 - Î³3*SR + (Î³4-3)/4*SR^2) / n)
        """
        sr = 1.0  # å‡è®¾ SR=1 è¿›è¡Œä¼°ç®—
        se_squared = (
            1 + 0.5 * sr**2
            - skewness * sr
            + (kurtosis - 3) / 4 * sr**2
        ) / n_observations

        return np.sqrt(se_squared)
```

### 3.3 å› å­åº“å»é‡ä¸å‘é‡æ£€ç´¢

#### ä»»åŠ¡ 7.1: å› å­å…¥åº“ Qdrant

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/api/factors/service.py`

```python
# åœ¨å› å­åˆ›å»º/è¯„ä¼°é€šè¿‡åå…¥åº“å‘é‡

async def _index_factor_to_vector_store(self, factor: Factor, metrics: FactorMetrics):
    """å°†å› å­ç´¢å¼•åˆ° Qdrant å‘é‡åº“"""
    from iqfmp.vector.store import VectorStore
    from iqfmp.vector.embedding import get_factor_embedding

    # 1. ç”Ÿæˆå› å­åµŒå…¥
    embedding = await get_factor_embedding(
        code=factor.code,
        description=factor.description,
        family=factor.family,
    )

    # 2. å‡†å¤‡å…ƒæ•°æ®
    metadata = {
        "factor_id": factor.id,
        "name": factor.name,
        "family": factor.family,
        "sharpe": metrics.sharpe,
        "ic_mean": metrics.ic_mean,
        "created_at": factor.created_at.isoformat(),
    }

    # 3. å­˜å…¥ Qdrant
    store = VectorStore()
    await store.upsert(
        collection="factors",
        id=factor.id,
        vector=embedding,
        metadata=metadata,
    )
```

#### ä»»åŠ¡ 7.2: å› å­ç”Ÿæˆå‰æŸ¥é‡

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/api/factors/service.py`

```python
async def generate_factor(self, request: FactorGenerateRequest) -> Factor:
    """ç”Ÿæˆå› å­ (å¸¦å»é‡æ£€æŸ¥)"""

    # 1. è°ƒç”¨ LLM ç”Ÿæˆå› å­ä»£ç 
    result = await self._generate_factor_code(request)

    # 2. ç›¸ä¼¼å› å­æ£€æŸ¥ (NEW)
    similar_factors = await self._check_similarity(result.code)

    if similar_factors:
        # è¿”å›æœ€ç›¸ä¼¼çš„å› å­ä¿¡æ¯ï¼Œè®©ç”¨æˆ·å†³å®š
        top_similar = similar_factors[0]
        if top_similar.similarity > 0.95:
            raise FactorDuplicateError(
                f"å› å­ä¸ '{top_similar.name}' é«˜åº¦ç›¸ä¼¼ (ç›¸ä¼¼åº¦: {top_similar.similarity:.2%})"
            )

        # ç›¸ä¼¼åº¦è¾ƒé«˜ä½†ä¸å®Œå…¨é‡å¤ï¼Œæ·»åŠ è­¦å‘Š
        result.warnings.append(
            f"å‘ç°ç›¸ä¼¼å› å­: {top_similar.name} (ç›¸ä¼¼åº¦: {top_similar.similarity:.2%})"
        )

    # 3. åˆ›å»ºå› å­
    return await self.create_factor(result)

async def _check_similarity(self, code: str) -> list[SimilarFactor]:
    """æ£€æŸ¥å› å­ä»£ç ç›¸ä¼¼åº¦"""
    from iqfmp.vector.store import VectorStore
    from iqfmp.vector.embedding import get_factor_embedding

    embedding = await get_factor_embedding(code=code)

    store = VectorStore()
    results = await store.search(
        collection="factors",
        vector=embedding,
        top_k=5,
        threshold=0.8,  # ç›¸ä¼¼åº¦é˜ˆå€¼
    )

    return [
        SimilarFactor(
            id=r.metadata["factor_id"],
            name=r.metadata["name"],
            similarity=r.score,
        )
        for r in results
    ]
```

### 3.4 ç­–ç•¥ä¸æ‰§è¡Œ

#### ä»»åŠ¡ 8.1: Qlib å›æµ‹é©±åŠ¨ç­–ç•¥ç”Ÿæˆ

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/strategy/generator.py`

```python
class StrategyGenerator:
    """åŸºäºå› å­è¯„ä¼°ç»“æœç”Ÿæˆç­–ç•¥"""

    async def generate_from_factors(
        self,
        factor_ids: list[str],
        combination_method: str = "equal_weight",
    ) -> Strategy:
        """
        ä»éªŒè¯é€šè¿‡çš„å› å­ç”Ÿæˆç­–ç•¥

        Args:
            factor_ids: å› å­ ID åˆ—è¡¨ (åº”æ¥è‡ªä¸åŒ cluster)
            combination_method: ç»„åˆæ–¹æ³• (equal_weight, ic_weight, optimization)
        """
        # 1. åŠ è½½å› å­
        factors = await self._load_factors(factor_ids)

        # 2. æ£€æŸ¥å› å­å¤šæ ·æ€§ (ä¸åŒ cluster)
        clusters = set(f.cluster_id for f in factors if f.cluster_id)
        if len(clusters) < len(factors) * 0.5:
            warnings.warn("å› å­å¤šæ ·æ€§ä¸è¶³ï¼Œå»ºè®®é€‰æ‹©ä¸åŒèšç±»çš„å› å­")

        # 3. ç”Ÿæˆç»„åˆæƒé‡
        if combination_method == "equal_weight":
            weights = {f.id: 1.0 / len(factors) for f in factors}
        elif combination_method == "ic_weight":
            weights = self._ic_weighted(factors)
        else:
            weights = await self._optimize_weights(factors)

        # 4. ç”Ÿæˆ Qlib ç­–ç•¥é…ç½®
        strategy_config = self._generate_qlib_strategy(factors, weights)

        # 5. åˆ›å»ºç­–ç•¥è®°å½•
        strategy = Strategy(
            id=str(uuid4()),
            name=f"combined_{len(factors)}factors",
            factor_weights=weights,
            qlib_config=strategy_config,
            created_at=datetime.now(),
        )

        return strategy
```

#### ä»»åŠ¡ 8.2: é£é™©æ§åˆ¶ç¡¬æ€§é˜ˆå€¼

**ä¿®æ”¹æ–‡ä»¶**: `src/iqfmp/exchange/risk.py`

```python
class RiskController:
    """é£é™©æ§åˆ¶å™¨ (å¸¦ç¡¬æ€§é˜ˆå€¼)"""

    # ç¡¬æ€§é˜ˆå€¼ (ä¸å¯è°ƒæ•´)
    MAX_DRAWDOWN_THRESHOLD = 0.15  # 15% æœ€å¤§å›æ’¤è§¦å‘å¹³ä»“
    MAX_POSITION_RATIO = 0.3      # å•ä¸€æŒä»“ä¸è¶…è¿‡ 30%
    MAX_LEVERAGE = 3.0            # æœ€å¤§æ æ† 3x
    EMERGENCY_LOSS_THRESHOLD = 0.05  # 5% å•æ—¥äºæŸè§¦å‘ç´§æ€¥å¹³ä»“

    async def check_risk(self, position: Position, account: Account) -> RiskCheckResult:
        """æ£€æŸ¥é£é™©å¹¶è¿”å›å»ºè®®åŠ¨ä½œ"""
        violations = []

        # 1. å›æ’¤æ£€æŸ¥
        drawdown = self._calculate_drawdown(account)
        if drawdown > self.MAX_DRAWDOWN_THRESHOLD:
            violations.append(RiskViolation(
                type="max_drawdown",
                severity="critical",
                action="emergency_close_all",
                message=f"æœ€å¤§å›æ’¤ {drawdown:.2%} è¶…è¿‡é˜ˆå€¼ {self.MAX_DRAWDOWN_THRESHOLD:.2%}",
            ))

        # 2. æŒä»“é›†ä¸­åº¦æ£€æŸ¥
        position_ratio = position.value / account.equity
        if position_ratio > self.MAX_POSITION_RATIO:
            violations.append(RiskViolation(
                type="position_concentration",
                severity="high",
                action="reduce_position",
                message=f"æŒä»“æ¯”ä¾‹ {position_ratio:.2%} è¶…è¿‡é˜ˆå€¼ {self.MAX_POSITION_RATIO:.2%}",
            ))

        # 3. æ æ†æ£€æŸ¥
        leverage = account.total_position_value / account.equity
        if leverage > self.MAX_LEVERAGE:
            violations.append(RiskViolation(
                type="leverage",
                severity="high",
                action="reduce_leverage",
                message=f"æ æ† {leverage:.2f}x è¶…è¿‡é˜ˆå€¼ {self.MAX_LEVERAGE}x",
            ))

        # 4. å•æ—¥äºæŸæ£€æŸ¥
        daily_pnl = self._get_daily_pnl(account)
        daily_loss_ratio = -daily_pnl / account.equity if daily_pnl < 0 else 0
        if daily_loss_ratio > self.EMERGENCY_LOSS_THRESHOLD:
            violations.append(RiskViolation(
                type="daily_loss",
                severity="critical",
                action="emergency_close_all",
                message=f"å•æ—¥äºæŸ {daily_loss_ratio:.2%} è¶…è¿‡é˜ˆå€¼ {self.EMERGENCY_LOSS_THRESHOLD:.2%}",
            ))

        return RiskCheckResult(
            is_safe=len(violations) == 0,
            violations=violations,
            recommended_action=self._get_recommended_action(violations),
        )
```

### 3.5 ç›‘æ§ä¸å¯è§†åŒ–

#### ä»»åŠ¡ 9.1: Prometheus æŒ‡æ ‡æš´éœ²

**æ–°å¢æ–‡ä»¶**: `src/iqfmp/monitoring/metrics.py`

```python
from prometheus_client import Counter, Histogram, Gauge

# LLM æŒ‡æ ‡
LLM_REQUEST_TOTAL = Counter(
    'iqfmp_llm_requests_total',
    'Total LLM API requests',
    ['model', 'status']
)
LLM_REQUEST_LATENCY = Histogram(
    'iqfmp_llm_request_latency_seconds',
    'LLM request latency',
    ['model'],
    buckets=[0.1, 0.5, 1, 2, 5, 10, 30, 60]
)
LLM_TOKEN_USAGE = Counter(
    'iqfmp_llm_tokens_total',
    'Total tokens used',
    ['model', 'type']  # type: prompt, completion
)

# å› å­æŒ‡æ ‡
FACTOR_GENERATION_TOTAL = Counter(
    'iqfmp_factors_generated_total',
    'Total factors generated',
    ['family', 'status']
)
FACTOR_EVALUATION_LATENCY = Histogram(
    'iqfmp_factor_evaluation_latency_seconds',
    'Factor evaluation latency',
    buckets=[1, 5, 10, 30, 60, 120]
)
FACTOR_PASS_RATE = Gauge(
    'iqfmp_factor_pass_rate',
    'Factor pass rate',
    ['family']
)

# å›æµ‹æŒ‡æ ‡
BACKTEST_DURATION = Histogram(
    'iqfmp_backtest_duration_seconds',
    'Backtest execution duration',
    buckets=[10, 30, 60, 120, 300, 600]
)

# ä»»åŠ¡é˜Ÿåˆ—æŒ‡æ ‡
TASK_QUEUE_LENGTH = Gauge(
    'iqfmp_task_queue_length',
    'Number of tasks in queue',
    ['queue']
)
```

#### ä»»åŠ¡ 9.2: å‰ç«¯ç›‘æ§å¤§å±

**æ–°å¢æ–‡ä»¶**: `dashboard/src/pages/MonitoringDashboardPage.tsx`

```typescript
export function MonitoringDashboardPage() {
  const { data: metrics, isLoading } = useSystemMetrics();

  return (
    <div className="grid grid-cols-3 gap-4 p-4">
      {/* LLM æ€§èƒ½ */}
      <Card>
        <CardHeader>LLM æ€§èƒ½</CardHeader>
        <CardContent>
          <div className="space-y-2">
            <MetricRow label="å¹³å‡å»¶è¿Ÿ" value={`${metrics?.llm.avgLatency}ms`} />
            <MetricRow label="æˆåŠŸç‡" value={`${metrics?.llm.successRate}%`} />
            <MetricRow label="ä»Šæ—¥ Token" value={metrics?.llm.tokensToday} />
          </div>
        </CardContent>
      </Card>

      {/* å› å­ç»Ÿè®¡ */}
      <Card>
        <CardHeader>å› å­ç”Ÿæˆ</CardHeader>
        <CardContent>
          <div className="space-y-2">
            <MetricRow label="ä»Šæ—¥ç”Ÿæˆ" value={metrics?.factors.generatedToday} />
            <MetricRow label="é€šè¿‡ç‡" value={`${metrics?.factors.passRate}%`} />
            <MetricRow label="å¹³å‡ Sharpe" value={metrics?.factors.avgSharpe?.toFixed(2)} />
          </div>
        </CardContent>
      </Card>

      {/* ä»»åŠ¡é˜Ÿåˆ— */}
      <Card>
        <CardHeader>ä»»åŠ¡é˜Ÿåˆ—</CardHeader>
        <CardContent>
          <div className="space-y-2">
            <MetricRow label="å¾…å¤„ç†" value={metrics?.queue.pending} />
            <MetricRow label="å¤„ç†ä¸­" value={metrics?.queue.active} />
            <MetricRow label="å·²å®Œæˆ" value={metrics?.queue.completed} />
          </div>
        </CardContent>
      </Card>

      {/* å› å­ç¨³å®šæ€§å›¾è¡¨ */}
      <Card className="col-span-2">
        <CardHeader>å› å­ç¨³å®šæ€§è¶‹åŠ¿</CardHeader>
        <CardContent>
          <StabilityChart data={metrics?.stabilityTrend} />
        </CardContent>
      </Card>

      {/* å®æ—¶æ—¥å¿— */}
      <Card>
        <CardHeader>å®æ—¶æ—¥å¿—</CardHeader>
        <CardContent>
          <LogStream channel="system" maxLines={20} />
        </CardContent>
      </Card>
    </div>
  );
}
```

---

## å››ã€ä»»åŠ¡ä¼˜å…ˆçº§çŸ©é˜µ

| ä¼˜å…ˆçº§ | ä»»åŠ¡ | å½±å“ | å·¥ä½œé‡ | ä¾èµ– |
|--------|------|------|--------|------|
| **P0** | 1.1 å› å­æŒä¹…åŒ–åˆ‡æ¢ DB | ğŸ”´ Critical | 2d | æ—  |
| **P0** | 2.1 æ¥å…¥å®Œæ•´ FactorEvaluator | ğŸ”´ Critical | 3d | 1.1 |
| **P0** | 1.2 Celery ä»»åŠ¡å†™å› DB | ğŸ”´ Critical | 2d | 1.1 |
| **P1** | 2.2 äº¤æ˜“æˆæœ¬æ¨¡å‹ | ğŸŸ¡ High | 2d | 2.1 |
| **P1** | 3.1 Qlib è¡¨è¾¾å¼è§£æä¿®å¤ | ğŸŸ¡ High | 3d | æ—  |
| **P1** | 4.1 System API çœŸå®æ•°æ® | ğŸŸ¡ High | 1d | 1.2 |
| **P1** | 4.2 WebSocket æ¨é€ | ğŸŸ¡ High | 2d | æ—  |
| **P2** | 5.1 RDLoop API æš´éœ² | ğŸŸ  Medium | 2d | 2.1 |
| **P2** | 6.1 CryptoCVSplitter å®Œå–„ | ğŸŸ  Medium | 2d | 2.1 |
| **P2** | 6.2 Deflated Sharpe é˜ˆå€¼ | ğŸŸ  Medium | 1d | æ—  |
| **P2** | 7.1 å› å­å…¥åº“ Qdrant | ğŸŸ  Medium | 2d | 2.1 |
| **P2** | 7.2 å› å­ç”Ÿæˆå‰æŸ¥é‡ | ğŸŸ  Medium | 1d | 7.1 |
| **P3** | 8.1 ç­–ç•¥ç”Ÿæˆå™¨ | ğŸŸ¢ Low | 3d | 7.1 |
| **P3** | 8.2 é£é™©æ§åˆ¶ç¡¬é˜ˆå€¼ | ğŸŸ¢ Low | 2d | æ—  |
| **P3** | 9.1 Prometheus æŒ‡æ ‡ | ğŸŸ¢ Low | 1d | æ—  |
| **P3** | 9.2 ç›‘æ§å¤§å± | ğŸŸ¢ Low | 2d | 9.1 |

---

## äº”ã€é¢„æœŸæˆæœ

### é˜¶æ®µ1å®Œæˆå (2-3å‘¨)

- âœ… å› å­åˆ›å»ºâ†’è¯„ä¼°â†’æŸ¥è¯¢å®Œæ•´é—­ç¯
- âœ… ç ”ç©¶è´¦æœ¬æŒä¹…åŒ–å¹¶å¯æŸ¥è¯¢
- âœ… Celery ä»»åŠ¡çœŸå®æ‰§è¡Œå¹¶å†™å› DB
- âœ… å‰ç«¯å¯å±•ç¤ºçœŸå®æ•°æ®
- âœ… WebSocket å®æ—¶æ¨é€

### é˜¶æ®µ2å®Œæˆå (4-6å‘¨)

- âœ… RD-Loop å¯é€šè¿‡ API å¯åŠ¨
- âœ… å› å­å»é‡å’Œå‘é‡æ£€ç´¢
- âœ… Deflated Sharpe åŠ¨æ€é˜ˆå€¼
- âœ… ç­–ç•¥è‡ªåŠ¨ç”Ÿæˆ
- âœ… å®Œæ•´ç›‘æ§ä½“ç³»

---

## å…­ã€é£é™©ä¸ç¼“è§£

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| Qlib è¡¨è¾¾å¼å…¼å®¹æ€§é—®é¢˜ | é«˜ | ä¸­ | ä¿ç•™æ‰‹å†™è§£æå™¨ä½œä¸ºé™çº§ |
| å‘é‡åº“åµŒå…¥æ¨¡å‹ä¾èµ– | ä¸­ | ä¸­ | ä½¿ç”¨æœ¬åœ° sentence-transformers |
| Celery ä»»åŠ¡å¡æ­» | ä¸­ | é«˜ | è®¾ç½® soft/hard timeout |
| WebSocket è¿æ¥æ•°è¿‡å¤š | ä½ | ä¸­ | ä½¿ç”¨è¿æ¥æ± å’Œé™æµ |

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: 2025-12-10*
*ç‰ˆæœ¬: 1.0*
