#!/bin/bash
#
# Redis å¤‡ä»½è„šæœ¬
# æ”¯æŒ RDB å¿«ç…§å’Œ AOF å¤‡ä»½
#
# ä½¿ç”¨æ–¹æ³•:
#   ./redis_backup.sh [rdb|aof|both]
#
# ç¯å¢ƒå˜é‡:
#   REDIS_HOST - Redis ä¸»æœº (é»˜è®¤: localhost)
#   REDIS_PORT - Redis ç«¯å£ (é»˜è®¤: 6379)
#   REDIS_PASSWORD - Redis å¯†ç  (å¯é€‰)
#   BACKUP_DIR - å¤‡ä»½ç›®å½• (é»˜è®¤: /var/backups/redis)
#   RETENTION_DAYS - ä¿ç•™å¤©æ•° (é»˜è®¤: 7)
#   S3_BUCKET - S3 å­˜å‚¨æ¡¶ (å¯é€‰)

set -euo pipefail

# ==================== é…ç½® ====================
REDIS_HOST="${REDIS_HOST:-localhost}"
REDIS_PORT="${REDIS_PORT:-6379}"
REDIS_PASSWORD="${REDIS_PASSWORD:-}"
BACKUP_DIR="${BACKUP_DIR:-/var/backups/redis}"
RETENTION_DAYS="${RETENTION_DAYS:-7}"
BACKUP_TYPE="${1:-both}"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Redis CLI å‘½ä»¤
if [[ -n "$REDIS_PASSWORD" ]]; then
    REDIS_CLI="redis-cli -h $REDIS_HOST -p $REDIS_PORT -a $REDIS_PASSWORD"
else
    REDIS_CLI="redis-cli -h $REDIS_HOST -p $REDIS_PORT"
fi

# æ—¥å¿—å‡½æ•°
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $1" >&2
    exit 1
}

# ==================== å‰ç½®æ£€æŸ¥ ====================
check_prerequisites() {
    log "æ£€æŸ¥å‰ç½®æ¡ä»¶..."

    # æ£€æŸ¥ redis-cli
    if ! command -v redis-cli &> /dev/null; then
        error "redis-cli æœªå®‰è£…"
    fi

    # æ£€æŸ¥ Redis è¿æ¥
    if ! $REDIS_CLI PING &> /dev/null; then
        error "æ— æ³•è¿æ¥åˆ° Redis"
    fi

    # åˆ›å»ºå¤‡ä»½ç›®å½•
    mkdir -p "$BACKUP_DIR"/{rdb,aof}

    log "å‰ç½®æ£€æŸ¥å®Œæˆ"
}

# ==================== RDB å¤‡ä»½ ====================
rdb_backup() {
    log "å¼€å§‹ RDB å¤‡ä»½..."

    # è§¦å‘ BGSAVE
    $REDIS_CLI BGSAVE

    # ç­‰å¾… BGSAVE å®Œæˆ
    log "ç­‰å¾… BGSAVE å®Œæˆ..."
    while [[ $($REDIS_CLI LASTSAVE) == $($REDIS_CLI LASTSAVE) ]]; do
        sleep 1
    done

    # è·å– RDB æ–‡ä»¶è·¯å¾„
    REDIS_DIR=$($REDIS_CLI CONFIG GET dir | tail -1)
    REDIS_DBFILENAME=$($REDIS_CLI CONFIG GET dbfilename | tail -1)
    RDB_FILE="$REDIS_DIR/$REDIS_DBFILENAME"

    # å¤åˆ¶ RDB æ–‡ä»¶
    BACKUP_FILE="$BACKUP_DIR/rdb/redis_${TIMESTAMP}.rdb"
    cp "$RDB_FILE" "$BACKUP_FILE"

    # å‹ç¼©
    gzip "$BACKUP_FILE"
    BACKUP_FILE="${BACKUP_FILE}.gz"

    # è®°å½•å…ƒæ•°æ®
    cat > "$BACKUP_DIR/rdb/redis_${TIMESTAMP}.meta" << EOF
{
    "type": "rdb",
    "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "file": "$BACKUP_FILE",
    "size": $(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE"),
    "checksum": "$(sha256sum "$BACKUP_FILE" | cut -d' ' -f1)"
}
EOF

    log "RDB å¤‡ä»½å®Œæˆ: $BACKUP_FILE"
    echo "$BACKUP_FILE"
}

# ==================== AOF å¤‡ä»½ ====================
aof_backup() {
    log "å¼€å§‹ AOF å¤‡ä»½..."

    # è§¦å‘ AOF é‡å†™ (å¦‚æœå¯ç”¨)
    AOF_ENABLED=$($REDIS_CLI CONFIG GET appendonly | tail -1)

    if [[ "$AOF_ENABLED" != "yes" ]]; then
        log "AOF æœªå¯ç”¨ï¼Œè·³è¿‡ AOF å¤‡ä»½"
        return
    fi

    # è§¦å‘ BGREWRITEAOF
    $REDIS_CLI BGREWRITEAOF

    # ç­‰å¾…å®Œæˆ
    log "ç­‰å¾… AOF é‡å†™å®Œæˆ..."
    while [[ $($REDIS_CLI INFO persistence | grep aof_rewrite_in_progress | cut -d: -f2 | tr -d '\r') == "1" ]]; do
        sleep 1
    done

    # è·å– AOF æ–‡ä»¶è·¯å¾„
    REDIS_DIR=$($REDIS_CLI CONFIG GET dir | tail -1)
    AOF_FILENAME=$($REDIS_CLI CONFIG GET appendfilename | tail -1)
    AOF_FILE="$REDIS_DIR/$AOF_FILENAME"

    # å¤åˆ¶ AOF æ–‡ä»¶
    BACKUP_FILE="$BACKUP_DIR/aof/redis_${TIMESTAMP}.aof"
    cp "$AOF_FILE" "$BACKUP_FILE"

    # å‹ç¼©
    gzip "$BACKUP_FILE"
    BACKUP_FILE="${BACKUP_FILE}.gz"

    # è®°å½•å…ƒæ•°æ®
    cat > "$BACKUP_DIR/aof/redis_${TIMESTAMP}.meta" << EOF
{
    "type": "aof",
    "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "file": "$BACKUP_FILE",
    "size": $(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE"),
    "checksum": "$(sha256sum "$BACKUP_FILE" | cut -d' ' -f1)"
}
EOF

    log "AOF å¤‡ä»½å®Œæˆ: $BACKUP_FILE"
    echo "$BACKUP_FILE"
}

# ==================== ä¸Šä¼ åˆ° S3 ====================
upload_to_s3() {
    local file="$1"

    if [[ -n "${S3_BUCKET:-}" ]]; then
        log "ä¸Šä¼ åˆ° S3: $S3_BUCKET"
        aws s3 cp "$file" "s3://$S3_BUCKET/redis/$(basename "$file")"
        log "S3 ä¸Šä¼ å®Œæˆ"
    fi
}

# ==================== æ¸…ç†æ—§å¤‡ä»½ ====================
cleanup_old_backups() {
    log "æ¸…ç† $RETENTION_DAYS å¤©å‰çš„å¤‡ä»½..."

    find "$BACKUP_DIR/rdb" -name "*.gz" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR/rdb" -name "*.meta" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR/aof" -name "*.gz" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR/aof" -name "*.meta" -mtime +$RETENTION_DAYS -delete

    log "æ¸…ç†å®Œæˆ"
}

# ==================== å‘é€é€šçŸ¥ ====================
send_notification() {
    local status="$1"
    local message="$2"

    if [[ -n "${TELEGRAM_BOT_TOKEN:-}" && -n "${TELEGRAM_CHAT_ID:-}" ]]; then
        curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
            -d chat_id="${TELEGRAM_CHAT_ID}" \
            -d text="ğŸ”´ Redis å¤‡ä»½ $status: $message" \
            -d parse_mode="HTML" > /dev/null || true
    fi
}

# ==================== ä¸»å‡½æ•° ====================
main() {
    log "========== Redis å¤‡ä»½å¼€å§‹ =========="
    log "å¤‡ä»½ç±»å‹: $BACKUP_TYPE"

    check_prerequisites

    case "$BACKUP_TYPE" in
        rdb)
            backup_file=$(rdb_backup)
            upload_to_s3 "$backup_file"
            ;;
        aof)
            backup_file=$(aof_backup)
            [[ -n "$backup_file" ]] && upload_to_s3 "$backup_file"
            ;;
        both)
            rdb_file=$(rdb_backup)
            upload_to_s3 "$rdb_file"

            aof_file=$(aof_backup)
            [[ -n "$aof_file" ]] && upload_to_s3 "$aof_file"
            ;;
        *)
            error "æœªçŸ¥çš„å¤‡ä»½ç±»å‹: $BACKUP_TYPE (æ”¯æŒ: rdb, aof, both)"
            ;;
    esac

    cleanup_old_backups

    send_notification "æˆåŠŸ" "å¤‡ä»½ç±»å‹: $BACKUP_TYPE"

    log "========== Redis å¤‡ä»½å®Œæˆ =========="
}

# æ‰§è¡Œ
main
