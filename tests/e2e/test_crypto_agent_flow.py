"""End-to-End Test for Crypto Agent Workflow.

This test simulates the full agent lifecycle:
1. Factor Generation (via Qlib FactorEngine)
2. Signal Conversion (via SignalConverter)
3. Strategy Backtest (via CryptoQlibBacktest)

It verifies that all components integrate correctly using:
- Real Qlib binary data (generated by verify_qlib_data.py)
- Real Qlib C++ expression engine
- Real Crypto settlement logic (funding/liquidation)
"""

import os
import shutil
import pytest
import pandas as pd
import numpy as np
from pathlib import Path

# Import core components
from iqfmp.core.factor_engine import QlibFactorEngine
from iqfmp.core.signal_converter import SignalConverter, SignalConfig
from iqfmp.core.crypto_backtest import CryptoQlibBacktest, CryptoBacktestConfig

# Test constants
DATA_DIR = Path("data/qlib_data_verify")
SYMBOL = "ethusdt"  # Lowercase for Qlib
FACTOR_EXPR = "Mean($close, 5) / $close - 1"  # Simple mean reversion

@pytest.fixture(scope="module")
def qlib_init():
    """Initialize Qlib with local data."""
    import qlib
    if not DATA_DIR.exists():
        pytest.skip(f"Data directory {DATA_DIR} not found. Run scripts/verify_qlib_data.py first.")
    
    # Initialize Qlib
    qlib.init(provider_uri=str(DATA_DIR.absolute()))
    return True

@pytest.mark.xfail(reason="Known issue: Series comparison bug in factor computation")
def test_full_agent_workflow(qlib_init):
    """Test the complete flow from factor to backtest."""
    print("\n" + "="*60)
    print("ðŸš€ Starting Crypto Agent Workflow E2E Test")
    print("="*60)

    # ---------------------------------------------------------
    # Step 1: Factor Generation (Factor Agent)
    # ---------------------------------------------------------
    print("\n[Step 1] Factor Generation...")
    engine = QlibFactorEngine(
        provider_uri=str(DATA_DIR.absolute()),
        instruments=[SYMBOL],
        symbol=SYMBOL
    )
    
    # Enable D.features path for C++ engine usage
    engine.enable_d_features(True)
    
    # Compute factor
    factor_values = engine.compute_factor(
        expression=FACTOR_EXPR,
        factor_name="mean_reversion_5d",
        start_time="2022-01-01",
        end_time="2025-12-31"
    )
    
    print(f"âœ… Factor computed: {len(factor_values)} rows")
    print(f"   Head: {factor_values.head(3).to_dict()}")
    
    assert len(factor_values) > 0, "Factor computation returned empty result"
    assert not factor_values.isna().all(), "Factor values are all NaN"

    # ---------------------------------------------------------
    # Step 2: Signal Conversion (Orchestrator) - MUST USE ML PATH
    # ---------------------------------------------------------
    print("\n[Step 2] Signal Conversion (ML-enabled)...")

    # CRITICAL: å¿…é¡»ä½¿ç”¨ ML ä¿¡å·ç”Ÿæˆè·¯å¾„ï¼Œè€Œéžç®€å•çš„ zscore
    # è¿™ç¡®ä¿ LightGBM æ¨¡åž‹å®žé™…è¢«è®­ç»ƒå’Œä½¿ç”¨
    from qlib.data import D

    # èŽ·å–ä»·æ ¼æ•°æ®ç”¨äºŽ ML ç‰¹å¾
    price_data = D.features(
        instruments=[SYMBOL],
        fields=["$close", "$open", "$high", "$low", "$volume"],
        start_time="2022-01-01",
        end_time="2025-12-31"
    )
    price_data.columns = [c.replace("$", "") for c in price_data.columns]
    if isinstance(price_data.index, pd.MultiIndex):
        price_data = price_data.loc[SYMBOL]

    # ä½¿ç”¨ ML ä¿¡å·ç”Ÿæˆå™¨
    converter = SignalConverter(SignalConfig(
        ml_signal_enabled=True,  # å¿…é¡»å¯ç”¨ ML ä¿¡å·
        ml_lookback_window=20,
        ml_forward_period=5,
        ml_n_estimators=50,
        ml_min_samples=50,
    ))

    signal = converter.to_signal(factor_values, price_data=price_data)
    print(f"âœ… ML Signal generated: {len(signal)} rows")
    print(f"   Non-zero signals: {(signal != 0).sum()}")

    # éªŒè¯ ML æ¨¡åž‹å®žé™…è¢«è®­ç»ƒ
    assert converter._ml_model is not None, (
        "ML model was NOT trained! This test is useless without real ML signal generation."
    )
    print(f"   âœ… LightGBM model trained: {converter._ml_train_count} time(s)")
    
    # Slice signal for the specific symbol if MultiIndex
    if isinstance(signal.index, pd.MultiIndex):
        try:
            signal = signal.loc[SYMBOL]
            print(f"   Sliced signal for {SYMBOL}, new shape: {signal.shape}")
        except KeyError:
            print(f"   Warning: Symbol {SYMBOL} not found in signal index")
            signal = signal.droplevel(0)
    
    assert len(signal) == len(factor_values) if isinstance(factor_values.index, pd.Index) else True

    # ---------------------------------------------------------
    # Step 3: Data Preparation for Backtest
    # ---------------------------------------------------------
    # We need OHLCV + Funding Rate for the backtest engine
    # Load it via Qlib D.features to ensure alignment
    from qlib.data import D
    price_data = D.features(
        instruments=[SYMBOL],
        fields=["$close", "$open", "$high", "$low", "$volume", "$funding_rate"],
        start_time="2022-01-01",
        end_time="2025-12-31"
    )
    
    # Rename columns to match backtest engine requirements (remove $ prefix)
    price_data.columns = [c.replace("$", "") for c in price_data.columns]
    
    # Qlib D.features returns MultiIndex (instrument, datetime)
    # We need to slice it for the specific symbol to get DatetimeIndex
    print(f"   D.features shape: {price_data.shape}")
    print(f"   Index type: {type(price_data.index)}")
    
    if isinstance(price_data.index, pd.MultiIndex):
        try:
            price_data = price_data.loc[SYMBOL]
            print(f"   Sliced for {SYMBOL}, new shape: {price_data.shape}")
        except KeyError:
            # Fallback if symbol casing mismatch
            print(f"   Warning: Symbol {SYMBOL} not found in index {price_data.index.get_level_values(0).unique()}")
            price_data = price_data.droplevel(0)
    
    # Check if we have funding rate data (might be missing in sample)
    if "funding_rate" not in price_data.columns:
        print("âš ï¸  Funding rate missing, adding dummy zeros")
        price_data["funding_rate"] = 0.0
    else:
        # Fill NaN funding rates
        price_data["funding_rate"] = price_data["funding_rate"].fillna(0.0)

    # ---------------------------------------------------------
    # Step 4: Backtest Execution (Strategy Agent)
    # ---------------------------------------------------------
    print("\n[Step 4] Strategy Backtest...")
    config = CryptoBacktestConfig(
        initial_capital=100_000.0,
        leverage=1,
        commission_rate=0.0005,
        slippage_rate=0.0001,
        funding_enabled=True
    )
    
    backtest_engine = CryptoQlibBacktest(config, [SYMBOL])
    
    # Align signal with price data
    signal_aligned = signal.reindex(price_data.index).fillna(0)
    
    result = backtest_engine.run(
        data=price_data,
        signals=signal_aligned,
        symbol=SYMBOL
    )
    
    print("\nðŸ“Š Backtest Results:")
    print(f"   Total Return: {result.total_return:.2%}")
    print(f"   Sharpe Ratio: {result.sharpe_ratio:.2f}")
    print(f"   Max Drawdown: {result.max_drawdown:.2%}")
    print(f"   Trades: {result.n_trades}")
    
    # ---------------------------------------------------------
    # Step 5: Assertions
    # ---------------------------------------------------------
    assert result.total_return != 0, "Backtest returned 0 return (did it run?)"
    assert result.n_trades > 0, "No trades executed"
    assert len(result.equity_curve) == len(price_data), "Equity curve length mismatch"
    
    print("\nâœ… E2E Workflow Test Passed!")


@pytest.mark.xfail(reason="Known issue: Series comparison bug in factor computation")
def test_ml_signal_generation(qlib_init):
    """Test ML-based signal generation using LightGBM.

    This test validates that:
    1. LightGBM is properly installed and importable
    2. ML signal generation actually trains a model
    3. Model predictions are converted to trading signals
    4. Signal values are within valid range (-1, 1)

    CRITICAL: This test MUST NOT pass if LightGBM is not installed.
    """
    print("\n" + "=" * 60)
    print("ðŸ§  Testing ML-based Signal Generation (LightGBM)")
    print("=" * 60)

    # Step 1: Verify LightGBM is installed (MUST fail if not)
    try:
        import lightgbm as lgb
        print(f"âœ… LightGBM version: {lgb.__version__}")
    except ImportError as e:
        pytest.fail(
            f"LightGBM is not installed but is required for ML signal generation. "
            f"Install with: pip install lightgbm. Error: {e}"
        )

    # Step 2: Prepare data
    from qlib.data import D

    price_data = D.features(
        instruments=[SYMBOL],
        fields=["$close", "$open", "$high", "$low", "$volume"],
        start_time="2022-01-01",
        end_time="2025-12-31"
    )
    price_data.columns = [c.replace("$", "") for c in price_data.columns]

    if isinstance(price_data.index, pd.MultiIndex):
        price_data = price_data.loc[SYMBOL]

    print(f"   Price data shape: {price_data.shape}")

    # Create factor values (simple momentum)
    factor_values = price_data["close"].pct_change(5)
    factor_values = factor_values.dropna()
    print(f"   Factor values shape: {factor_values.shape}")

    # Step 3: Create ML-enabled SignalConverter
    from iqfmp.core.signal_converter import SignalConverter, SignalConfig

    ml_config = SignalConfig(
        ml_signal_enabled=True,  # Enable ML signal
        ml_lookback_window=20,   # Shorter window for test
        ml_forward_period=5,
        ml_n_estimators=50,      # Fewer trees for speed
        ml_min_samples=50,       # Lower threshold for test data
    )

    converter = SignalConverter(ml_config)

    # Step 4: Generate ML signal (this MUST train a real model)
    print("\n[Step 4] Generating ML signal (training LightGBM)...")

    signal = converter.to_signal(factor_values, price_data=price_data)

    print(f"âœ… ML Signal generated: {len(signal)} rows")
    print(f"   Non-zero signals: {(signal != 0).sum()}")
    print(f"   Signal range: [{signal.min():.4f}, {signal.max():.4f}]")

    # Step 5: Assertions
    # Signal must not be all zeros (model must have learned something)
    assert (signal != 0).sum() > 0, "ML signal is all zeros - model did not learn"

    # Signal must be in valid range
    assert signal.min() >= -1.0, f"Signal below -1: {signal.min()}"
    assert signal.max() <= 1.0, f"Signal above 1: {signal.max()}"

    # Model must have been trained (internal state check)
    assert converter._ml_model is not None, "ML model was not trained"
    assert converter._ml_train_count > 0, "Training counter is 0"

    # Check feature importance (model learned from features)
    feature_importance = converter._ml_model.feature_importances_
    assert len(feature_importance) > 0, "No feature importance"
    assert sum(feature_importance) > 0, "All feature importances are 0"

    print(f"\nâœ… ML Signal Generation Test Passed!")
    print(f"   Model trained {converter._ml_train_count} time(s)")
    print(f"   Top 3 features: {converter._ml_feature_names[:3]}")


def test_strict_cv_mode_raises_on_insufficient_data():
    """Test that strict CV mode raises InsufficientDataError.

    This test validates that:
    1. strict_cv_mode=True (default) raises exception on insufficient data
    2. InsufficientDataError contains useful diagnostic info
    3. The error message clearly states what's needed

    CRITICAL: This test MUST fail if the code silently returns prob_overfit=1.0
    """
    print("\n" + "=" * 60)
    print("ðŸ”’ Testing Strict CV Mode (InsufficientDataError)")
    print("=" * 60)

    from iqfmp.core.crypto_backtest import (
        CryptoQlibBacktest,
        CryptoBacktestConfig,
        InsufficientDataError,
    )

    # Create config with strict mode (default)
    config = CryptoBacktestConfig(
        initial_capital=100_000.0,
        leverage=1,
        strict_cv_mode=True,  # Explicit for clarity
    )

    backtest = CryptoQlibBacktest(config, ["btcusdt"])

    # Create intentionally small dataset (< n_splits * 50 = 250 samples)
    small_equity = pd.Series(
        np.random.randn(100).cumsum() + 100_000,  # Only 100 samples
        index=pd.date_range("2024-01-01", periods=100, freq="1D"),
    )

    print(f"   Testing with {len(small_equity)} samples (need 250)")

    # CRITICAL: This MUST raise InsufficientDataError
    with pytest.raises(InsufficientDataError) as exc_info:
        backtest._calculate_cv_metrics(small_equity, n_splits=5)

    # Verify error contains useful information
    error = exc_info.value
    assert error.required_samples == 250, f"Expected 250, got {error.required_samples}"
    assert error.actual_samples == 100, f"Expected 100, got {error.actual_samples}"
    assert "Insufficient data" in str(error), "Error message should mention 'Insufficient data'"

    print(f"âœ… InsufficientDataError correctly raised!")
    print(f"   Required: {error.required_samples}, Actual: {error.actual_samples}")
    print(f"   Message: {str(error)[:80]}...")


def test_non_strict_cv_mode_returns_nan():
    """Test that non-strict CV mode returns NaN instead of misleading 1.0.

    This validates that when strict_cv_mode=False:
    1. No exception is raised
    2. prob_overfit is NaN (not 1.0 which is misleading)
    3. All metrics are NaN (indicating "unknown", not "bad")
    """
    print("\n" + "=" * 60)
    print("ðŸ“Š Testing Non-Strict CV Mode (NaN values)")
    print("=" * 60)

    from iqfmp.core.crypto_backtest import CryptoQlibBacktest, CryptoBacktestConfig

    # Create config with strict mode OFF
    config = CryptoBacktestConfig(
        initial_capital=100_000.0,
        leverage=1,
        strict_cv_mode=False,  # Disable strict mode
    )

    backtest = CryptoQlibBacktest(config, ["btcusdt"])

    # Small dataset
    small_equity = pd.Series(
        np.random.randn(100).cumsum() + 100_000,
        index=pd.date_range("2024-01-01", periods=100, freq="1D"),
    )

    # Should NOT raise, should return NaN values
    result = backtest._calculate_cv_metrics(small_equity, n_splits=5)

    print(f"   Result: {result}")

    # CRITICAL: prob_overfit must be NaN, NOT 1.0
    assert np.isnan(result["prob_overfit"]), (
        f"prob_overfit should be NaN, got {result['prob_overfit']}. "
        "1.0 is MISLEADING because it suggests 'definitely overfit' when we just don't know."
    )
    assert np.isnan(result["cv_sharpe_mean"]), "cv_sharpe_mean should be NaN"
    assert np.isnan(result["deflated_sharpe"]), "deflated_sharpe should be NaN"
    assert result["n_folds"] == 0, "n_folds should be 0"

    print("âœ… Non-strict mode correctly returns NaN values!")
    print("   NaN indicates 'unknown' rather than misleading '100% overfit'")


if __name__ == "__main__":
    # Manually run if executed as script
    try:
        class MockQlib: pass
        qlib_fixture = MockQlib()
        test_full_agent_workflow(qlib_fixture)
    except Exception as e:
        print(f"\nâŒ Test Failed: {e}")
        import traceback
        traceback.print_exc()
